{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArifAygun/CustomerEye/blob/main/Company_Reviews(Master2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cATpMArqxccp"
      },
      "source": [
        "#### IMPORT LIBRARIES AND DATASET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycountry\n",
        "!pip install emoji"
      ],
      "metadata": {
        "id": "qwfKsV5ewLav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd46727-9620-49a5-f54c-dd69614356b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (23.12.11)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.5/397.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PHHa63S7NpXC",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94aa018-aec0-4283-91fb-0181738611aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.dates as mdates\n",
        "import pycountry\n",
        "\n",
        "import emoji\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/Analysis_1/\n",
        "\n",
        "# Read CSV files into DataFrames\n",
        "df1 = pd.read_csv('Freedom_Debt_Relief2.csv')\n",
        "df2 = pd.read_csv('Millennium_Trust2.csv')\n",
        "df3 = pd.read_csv('Advance_America2.csv')\n",
        "\n",
        "print(df1.info(), df1.head())\n",
        "print(df2.info(), df2.head())\n",
        "print(df3.info(), df3.head())"
      ],
      "metadata": {
        "id": "GvtJHxqgQB3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144041c3-f4e2-4ba1-a351-76b0de4101a1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/Analysis_1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Year             2000 non-null   float64\n",
            " 1   Experience Date  2000 non-null   object \n",
            " 2   Review Date      2000 non-null   object \n",
            " 3   Reply Date       2000 non-null   object \n",
            " 4   Exp to Review    2000 non-null   int64  \n",
            " 5   Review to Reply  2000 non-null   int64  \n",
            " 6   Rating           2000 non-null   int64  \n",
            " 7   Countries        2000 non-null   object \n",
            " 8   Reviews          2000 non-null   object \n",
            " 9   Replies          2000 non-null   object \n",
            "dtypes: float64(1), int64(3), object(6)\n",
            "memory usage: 156.4+ KB\n",
            "None      Year Experience Date Review Date  Reply Date  Exp to Review  \\\n",
            "0  2021.0      2021-04-30  2021-04-30  2021-05-03              0   \n",
            "1  2022.0      2022-07-13  2022-07-13  2022-07-13              0   \n",
            "2  2021.0      2021-07-14  2021-07-14  2021-07-15              0   \n",
            "3  2022.0      2022-03-26  2022-03-26  2022-03-28              0   \n",
            "4  2023.0      2023-01-27  2023-01-27  2023-01-30              0   \n",
            "\n",
            "   Review to Reply  Rating      Countries  \\\n",
            "0                3       4  United States   \n",
            "1                0       5  United States   \n",
            "2                1       5  United States   \n",
            "3                2       2  United States   \n",
            "4                3       5  United States   \n",
            "\n",
            "                                             Reviews  \\\n",
            "0  FDR OVERSIGHT I typically would give FDR a 5 s...   \n",
            "1  Freedom has really helped with my debt… Freedo...   \n",
            "2  Everything is following through just as… Every...   \n",
            "3  Started the program owing a little… Started th...   \n",
            "4  I was surprised to have a settlement so… I was...   \n",
            "\n",
            "                                             Replies  \n",
            "0  We're disappointed to hear about the recent ex...  \n",
            "1  That is amazing to hear, Lashawn. It's rewardi...  \n",
            "2  That's great to hear, Ms. Castro. Preparing ou...  \n",
            "3  We never intended to disappoint you. Unfortuna...  \n",
            "4  We are glad to hear that, Abigail! We are happ...  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Year             2000 non-null   float64\n",
            " 1   Experience Date  2000 non-null   object \n",
            " 2   Review Date      2000 non-null   object \n",
            " 3   Reply Date       2000 non-null   object \n",
            " 4   Exp to Review    2000 non-null   int64  \n",
            " 5   Review to Reply  2000 non-null   int64  \n",
            " 6   Rating           2000 non-null   int64  \n",
            " 7   Countries        2000 non-null   object \n",
            " 8   Reviews          2000 non-null   object \n",
            " 9   Replies          2000 non-null   object \n",
            "dtypes: float64(1), int64(3), object(6)\n",
            "memory usage: 156.4+ KB\n",
            "None      Year Experience Date Review Date  Reply Date  Exp to Review  \\\n",
            "0  2023.0      2023-10-16  2023-10-16  2023-10-17              0   \n",
            "1  2023.0      2023-08-08  2023-08-08  2023-08-09              0   \n",
            "2  2021.0      2021-05-20  2021-05-20  2021-05-20              0   \n",
            "3  2023.0      2023-09-19  2023-09-26  2023-09-27              7   \n",
            "4  2023.0      2023-08-31  2023-08-31  2023-09-01              0   \n",
            "\n",
            "   Review to Reply  Rating      Countries  \\\n",
            "0                1       4  United States   \n",
            "1                1       5  United States   \n",
            "2                0       4  United States   \n",
            "3                1       5  United States   \n",
            "4                1       5  United States   \n",
            "\n",
            "                                             Reviews  \\\n",
            "0                  Website was easy to navigate. nan   \n",
            "1                           5 star Excellent service   \n",
            "2  Moving monies Getting all my investments in on...   \n",
            "3  The service was excellent The service was exce...   \n",
            "4  User Friendly It was very simple to use and fi...   \n",
            "\n",
            "                                             Replies  \n",
            "0   Thank you for taking the time to leave a review!  \n",
            "1  Thank you for the 5 star review!  We appreciat...  \n",
            "2    We are glad to hear you had a great experience!  \n",
            "3  Thank you for the 5 star review!  We appreciat...  \n",
            "4  We are so happy you had a good experience!  Th...  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Year             2000 non-null   float64\n",
            " 1   Experience Date  2000 non-null   object \n",
            " 2   Review Date      2000 non-null   object \n",
            " 3   Reply Date       2000 non-null   object \n",
            " 4   Exp to Review    2000 non-null   int64  \n",
            " 5   Review to Reply  2000 non-null   int64  \n",
            " 6   Rating           2000 non-null   int64  \n",
            " 7   Countries        2000 non-null   object \n",
            " 8   Reviews          2000 non-null   object \n",
            " 9   Replies          2000 non-null   object \n",
            "dtypes: float64(1), int64(3), object(6)\n",
            "memory usage: 156.4+ KB\n",
            "None      Year Experience Date Review Date  Reply Date  Exp to Review  \\\n",
            "0  2022.0      2022-12-02  2022-12-05  2022-12-05              3   \n",
            "1  2023.0      2023-03-30  2023-03-31  2023-03-31              1   \n",
            "2  2022.0      2022-05-26  2022-05-26  2022-05-26              0   \n",
            "3  2022.0      2022-11-16  2022-11-21  2022-11-21              5   \n",
            "4  2021.0      2021-12-06  2021-12-06  2021-12-06              0   \n",
            "\n",
            "   Review to Reply  Rating      Countries  \\\n",
            "0                0       5  United States   \n",
            "1                0       5  United States   \n",
            "2                0       5  United States   \n",
            "3                0       5  United States   \n",
            "4                0       5  United States   \n",
            "\n",
            "                                             Reviews  \\\n",
            "0  Great place for payday loans Employees are ver...   \n",
            "1  Vanessa at was so helpful Vanessa at was so he...   \n",
            "2  Very lovely ladies working at riverton… Very l...   \n",
            "3  On line lending process is relatively… On line...   \n",
            "4  The easiest loan possibe The easiest loan poss...   \n",
            "\n",
            "                                             Replies  \n",
            "0  Thank you for your positive review. At Advance...  \n",
            "1  Thank you for your positive review. At Advance...  \n",
            "2  -Thank you for your positive review. At Advanc...  \n",
            "3  Thank you for your positive review. At Advance...  \n",
            "4  -Thank you for your positive review. At Advanc...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oCE2RZtPmyS"
      },
      "source": [
        "## TEXT PREPROCESSING\n",
        "\n",
        "\n",
        "Before performing NLP tasks, it's important to preprocess the text data, which typically involves removing stopwords, punctuation, and converting text to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_for_sentiment_analysis(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Tokenization\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # Handle emojis\n",
        "    words = [emoji.demojize(word, delimiters=('', ' ')) for word in words]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    cleaned_text = ' '.join(words)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply the preprocessing function to the \"Reviews\" column in each DataFrame\n",
        "df1['Cleaned_Reviews'] = df1['Reviews'].apply(preprocess_text_for_sentiment_analysis)\n",
        "df2['Cleaned_Reviews'] = df2['Reviews'].apply(preprocess_text_for_sentiment_analysis)\n",
        "df3['Cleaned_Reviews'] = df3['Reviews'].apply(preprocess_text_for_sentiment_analysis)\n",
        "\n",
        "# Display the cleaned data\n",
        "print(\"Cleaned DataFrame 1:\")\n",
        "print(df1[['Reviews', 'Cleaned_Reviews']].head())\n",
        "\n",
        "print(\"\\nCleaned DataFrame 2:\")\n",
        "print(df2[['Reviews', 'Cleaned_Reviews']].head())\n",
        "\n",
        "print(\"\\nCleaned DataFrame 3:\")\n",
        "print(df3[['Reviews', 'Cleaned_Reviews']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fBvIYCldRP6",
        "outputId": "cd165e7b-3131-47ef-83bf-08d2718c0546"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned DataFrame 1:\n",
            "                                             Reviews  \\\n",
            "0  FDR OVERSIGHT I typically would give FDR a 5 s...   \n",
            "1  Freedom has really helped with my debt… Freedo...   \n",
            "2  Everything is following through just as… Every...   \n",
            "3  Started the program owing a little… Started th...   \n",
            "4  I was surprised to have a settlement so… I was...   \n",
            "\n",
            "                                     Cleaned_Reviews  \n",
            "0  fdr oversight typic would give fdr star rate f...  \n",
            "1  freedom realli help debt freedom realli help d...  \n",
            "2  everyth follow everyth follow explain would be...  \n",
            "3  start program owe littl start program owe litt...  \n",
            "4      surpris settlement surpris settlement quickli  \n",
            "\n",
            "Cleaned DataFrame 2:\n",
            "                                             Reviews  \\\n",
            "0                  Website was easy to navigate. nan   \n",
            "1                           5 star Excellent service   \n",
            "2  Moving monies Getting all my investments in on...   \n",
            "3  The service was excellent The service was exce...   \n",
            "4  User Friendly It was very simple to use and fi...   \n",
            "\n",
            "                                     Cleaned_Reviews  \n",
            "0                              websit easi navig nan  \n",
            "1                                  star excel servic  \n",
            "2           move moni get invest one place went well  \n",
            "3  servic excel servic excel abl complet transact...  \n",
            "4                  user friendli simpl use find need  \n",
            "\n",
            "Cleaned DataFrame 3:\n",
            "                                             Reviews  \\\n",
            "0  Great place for payday loans Employees are ver...   \n",
            "1  Vanessa at was so helpful Vanessa at was so he...   \n",
            "2  Very lovely ladies working at riverton… Very l...   \n",
            "3  On line lending process is relatively… On line...   \n",
            "4  The easiest loan possibe The easiest loan poss...   \n",
            "\n",
            "                                     Cleaned_Reviews  \n",
            "0         great place payday loan employe profession  \n",
            "1  vanessa help vanessa help abl get payday advan...  \n",
            "2  love ladi work riverton love ladi work riverto...  \n",
            "3  line lend process rel line lend process rel ea...  \n",
            "4  easiest loan possib easiest loan possibl never...  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}